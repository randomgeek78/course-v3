{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"minst\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fabbb143828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[5].reshape((28, 28)), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.1059, -2.0064, -2.0603, -2.8407, -2.8436, -2.2230, -2.2260, -2.6187,\n",
       "         -2.0055, -2.5764], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "XB = xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4043, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "YB = yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1094)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2282, grad_fn=<NegBackward>) tensor(0.9531)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(XB), YB), accuracy(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2282, grad_fn=<NllLossBackward>) tensor(0.9531)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(XB), YB), accuracy(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4421, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2246, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3587, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2278, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.utils.data.dataset.TensorDataset,\n",
       " torch.utils.data.dataset.Dataset,\n",
       " object]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDataset.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? torch.utils.data.dataset.Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2271, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "fit()\n",
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2243, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "fit()\n",
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2291, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "fit()\n",
    "print(loss_func(model(XB), YB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3025)\n",
      "1 tensor(0.2795)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_func(model(xb), yb)\n",
    "                             for xb, yb in valid_dl)\n",
    "        \n",
    "        print(epoch, valid_loss / len(valid_dl))\n",
    "        \n",
    "fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        losses, nums = zip(\n",
    "            *[loss_batch(model, loss_func, xb, yb, opt)\n",
    "                 for xb, yb in train_dl]                \n",
    "        )\n",
    "        train_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb)\n",
    "                     for xb, yb in valid_dl]                \n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        print(epoch, train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-92ecc9f3d1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-89e010a5b939>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m      4\u001b[0m         losses, nums = zip(\n\u001b[1;32m      5\u001b[0m             *[loss_batch(model, loss_func, xb.to(dev), yb.to(dev), opt)\n\u001b[0;32m----> 6\u001b[0;31m                  for xb, yb in train_dl]                \n\u001b[0m\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-89e010a5b939>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m         losses, nums = zip(\n\u001b[1;32m      5\u001b[0m             *[loss_batch(model, loss_func, xb.to(dev), yb.to(dev), opt)\n\u001b[0;32m----> 6\u001b[0;31m                  for xb, yb in train_dl]                \n\u001b[0m\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-6df68e1ec7a8>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-1a97866861e2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9959399934768676 1.4384264266967774\n",
      "1 1.0452902437973022 0.80487557888031\n",
      "2 0.6492620362472534 0.87469080452919\n",
      "3 0.5074708847999573 0.6494536604881287\n",
      "4 0.4411916031742096 0.5007925837516785\n",
      "5 0.3915911350631714 0.48884581896066664\n",
      "6 0.3577241226673126 0.596739467048645\n",
      "7 0.32865236943006515 0.3171803794026375\n",
      "8 0.3085102225112915 0.2533670735478401\n",
      "9 0.2892756531715393 0.40950921683311464\n",
      "CPU times: user 1min 59s, sys: 2min 21s, total: 4min 21s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"0 1.884198247871399 1.7993913557052612\n",
    "1 1.028207616996765 0.9597938510894776\n",
    "2 0.6326904792022705 0.662359540939331\n",
    "3 0.4660184606742859 0.5069415043830872\n",
    "4 0.39378326712608336 0.3938294437289238\n",
    "5 0.34074171547412874 0.39892419402599333\n",
    "6 0.30934994311332703 0.26812866797447205\n",
    "7 0.28931416080594063 0.2313538080573082\n",
    "8 0.2715235705566406 0.2718715633392334\n",
    "9 0.25853731740951535 0.3269713812470436\"\"\"\n",
    "err = np.array([x.split() for x in data.split(\"\\n\")], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fabadd9a048>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(err[:, [1,2]])\n",
    "plt.legend([\"train\", \"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.12744857326686382 0.11925731830894946\n",
      "1 0.12481816028118134 0.11660798535943032\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "epochs = 2\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9560174369239807 0.44269836435317994\n",
      "1 0.3523439505290985 0.23187437200546265\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8763231941604614 0.3575656952381134\n",
      "1 0.3138229029750824 0.2148989369392395\n"
     ]
    }
   ],
   "source": [
    "model = model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
